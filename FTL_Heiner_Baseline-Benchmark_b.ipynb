{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with file C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few\\synthetic_dataprep_B_with_deathtime_new_1GB_SSD.csv\n",
      "Min LBA in the dataset : 0\n",
      "Max LBA in the dataset : 262144\n",
      "Number of unique LBAs in the data : 262145\n",
      "Number of IO Accesses : 1310725\n"
     ]
    }
   ],
   "source": [
    "# Loading required libraries\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Loading trace : Needs to expanded into 4K chunks\n",
    "path = r'C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few'\n",
    "all_files = glob.glob(os.path.join(path, \"synthetic_dataprep_B_with_deathtime_new_1GB_SSD.csv\"))\n",
    "\n",
    "f = all_files[0]  # Change the file name as required\n",
    "print(\"Working with file \" + str(f))\n",
    "cols = ['IO_Num','LBA','Deathtime_RWI']\n",
    "df = pd.read_csv(f,engine='python',skiprows =1,header=None,na_values=['-1'], index_col=False)\n",
    "df.columns = cols\n",
    "df['Deathtime_RWI'] = df['Deathtime_RWI'].replace(np.NaN, -1)\n",
    "lba_list = df['LBA'].tolist()\n",
    "print(\"Min LBA in the dataset :\", min(lba_list))\n",
    "print(\"Max LBA in the dataset :\", max(lba_list))\n",
    "print(\"Number of unique LBAs in the data :\",len(Counter(df['LBA'])))\n",
    "print(\"Number of IO Accesses :\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference 8.5\n",
      "Looks good.Go ahead!\n"
     ]
    }
   ],
   "source": [
    "# SSD specifications\n",
    "page_size = 4096\n",
    "page_per_block = 64                          # Hyperparameter \n",
    "over_provisioning_ratio = 0.3 \n",
    "GB = 1024*1024*1024\n",
    "SSD_size_GB = 1.349 * GB\n",
    "ssd_capacity = SSD_size_GB                    # Hyperparameter                     \n",
    "LOG_PAGE_PER_BLOCK = int(math.log(page_per_block,2))\n",
    "\n",
    "\n",
    "\n",
    "# Make the block,page and physical addresses for normal and Overprovisioned capacity\n",
    "page_addresses = []\n",
    "block_addresses = []\n",
    "block_placement = 0\n",
    "start_counter = -1\n",
    "block_addresses.append(0)\n",
    "\n",
    "while(start_counter < (ssd_capacity/page_size) - page_size):\n",
    "    start_counter = start_counter + 1\n",
    "    page_addresses.append(int(start_counter))\n",
    "    if(block_placement >= page_per_block):\n",
    "        block_addresses.append(int(start_counter))\n",
    "        block_placement = 0\n",
    "\n",
    "    block_placement = block_placement + 1\n",
    "\n",
    "free_list_block = copy.deepcopy(block_addresses)\n",
    "free_list_page = copy.deepcopy(page_addresses)\n",
    "\n",
    "# Defining block_structure\n",
    "valid_bitmap = []\n",
    "write_ptr=0\n",
    "invalid_pages=0\n",
    "block_struct = {}\n",
    "\n",
    "for x in free_list_block:\n",
    "    start_lba = x\n",
    "    valid_bitmap = []\n",
    "    for x in range(page_per_block):\n",
    "        valid_bitmap.append(False)\n",
    "    segment = [start_lba,invalid_pages,valid_bitmap,write_ptr]\n",
    "    block_struct[start_lba]=segment\n",
    "    \n",
    "GC_THRESHOLD = int(0.25*len(block_addresses))\n",
    "if(len(page_addresses)*0.75 < len(Counter(df['LBA']))):\n",
    "    print(\"WARNING...! Not enough blocks. Need to increase SSD Size\")\n",
    "else:\n",
    "    print('Difference',(len(page_addresses)*0.75) - (len(Counter(df['LBA']))))\n",
    "    print(\"Looks good.Go ahead!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invalidate_lba(lba):\n",
    "    prev = L2P[lba]\n",
    "    prev_block = (prev >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "    prev_page = prev % page_per_block\n",
    "    block_details = block_struct[prev_block]                                 # Getting block details\n",
    "    block_struct[prev_block][2][prev_page] = False                           # Setting bitmap to False\n",
    "    block_struct[prev_block][1] = block_struct[cur_block][2].count(True)     # Setting invalid pages\n",
    "    L2P.pop(lba)\n",
    "    \n",
    "\n",
    "def map_lba(lba,cur_block):\n",
    "    phys_addr = block_struct[cur_block][0] + block_struct[cur_block][3]\n",
    "    L2P[lba] = phys_addr\n",
    "    P2L[phys_addr] = lba   \n",
    "    block_struct[cur_block][2][block_struct[cur_block][3]] =  True               # Setting Bitmap\n",
    "    block_struct[cur_block][1] =  block_struct[cur_block][2].count(True)         # Setting invalid pages\n",
    "    block_struct[cur_block][3] = block_struct[cur_block][3] + 1                  # Increasing Write pointer\n",
    "    \n",
    "def check_GC (cur_block, in_gc):\n",
    "    if (block_struct[cur_block][3] < page_per_block):\n",
    "        return cur_block\n",
    "    else:\n",
    "        closed_blocks.append(cur_block)\n",
    "        if(len(free_list_block) <= 0):\n",
    "            print(\"FAIL WHILE DOING GC, RAN OUT OF BLOCKS\") \n",
    "        elif (len(free_list_block) <= GC_THRESHOLD):\n",
    "            if(in_gc != True):\n",
    "                if(block_struct[cur_block][3] >= page_per_block):\n",
    "                    cur_block = free_list_block.pop(0)\n",
    "                in_gc = do_greedy_gc(cur_block,in_gc)\n",
    "        if(block_struct[cur_block][3] == (page_per_block)):\n",
    "            cur_block = free_list_block.pop(0)\n",
    "        return cur_block\n",
    "\n",
    "def do_greedy_gc(cur_block,in_gc):\n",
    "    in_gc = True\n",
    "    gc_writes = 0\n",
    "    page_per_block = 64\n",
    "    min_val = float('inf')  \n",
    "    for x in closed_blocks:               \n",
    "        if (block_struct[x][1] < min_val):\n",
    "            min_val = block_struct[x][1]\n",
    "            gc_blk = x\n",
    "\n",
    "    \n",
    "    #found the block with minimal valid pages, move all valid pages\n",
    "    for pg in range(page_per_block):\n",
    "        #figure out the logical addresses for all phys pages in the gc block\n",
    "        phys_addr = block_struct[gc_blk][0] + pg\n",
    "        gc_lba = P2L[phys_addr]\n",
    "        P2L.pop(gc_lba)\n",
    "        \n",
    "        # Checking for valid bitmap\n",
    "        prev_block = (phys_addr >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "        prev_page = phys_addr % page_per_block\n",
    "        bitmap = block_struct[prev_block][2][prev_page]\n",
    "        # If valid bitmap is True (data is valid), copy to OP capacity, increase GC writes\n",
    "        if (bitmap == True):\n",
    "            invalidate_lba(gc_lba)\n",
    "            #check if we need to get a new block\n",
    "            cur_block = check_GC(cur_block,in_gc)\n",
    "            #move the gc'ed block t-o a new location\n",
    "            map_lba(gc_lba,cur_block)   \n",
    "            gc_writes = gc_writes + 1\n",
    "           \n",
    "            \n",
    "    if(gc_writes > 64):\n",
    "        print(\"GC writes not as expected\", gc_writes)\n",
    "        \n",
    "    # Reset block details, remove from closed list and add to free_list\n",
    "    invalid_pages = 0\n",
    "    valid_bitmap = []\n",
    "    write_ptr = 0\n",
    "    for x in range(page_per_block):\n",
    "        valid_bitmap.append(False)\n",
    "        \n",
    "    block_struct[gc_blk]= [gc_blk,invalid_pages,valid_bitmap,write_ptr]\n",
    "    closed_blocks.remove(gc_blk)\n",
    "    free_list_block.append(gc_blk)\n",
    "    total_gc_writes[0] = total_gc_writes[0] + gc_writes\n",
    "    in_gc = False\n",
    "    return in_gc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Threshold set 1365\n",
      "Percentage completed in (%)  : 7.629365427530566\n",
      "Percentage completed in (%)  : 11.444048141295848\n",
      "Percentage completed in (%)  : 15.258730855061131\n",
      "Percentage completed in (%)  : 19.073413568826414\n",
      "Percentage completed in (%)  : 22.888096282591697\n",
      "Percentage completed in (%)  : 26.70277899635698\n",
      "Percentage completed in (%)  : 30.517461710122262\n",
      "Percentage completed in (%)  : 34.33214442388754\n",
      "Percentage completed in (%)  : 38.14682713765283\n",
      "Percentage completed in (%)  : 41.961509851418114\n",
      "Percentage completed in (%)  : 45.77619256518339\n",
      "Percentage completed in (%)  : 49.59087527894867\n",
      "Percentage completed in (%)  : 53.40555799271396\n",
      "Percentage completed in (%)  : 57.220240706479245\n",
      "Percentage completed in (%)  : 61.034923420244525\n",
      "Percentage completed in (%)  : 64.8496061340098\n",
      "Percentage completed in (%)  : 68.66428884777508\n",
      "Percentage completed in (%)  : 72.47897156154038\n",
      "Percentage completed in (%)  : 76.29365427530566\n",
      "Percentage completed in (%)  : 80.10833698907093\n",
      "Percentage completed in (%)  : 83.92301970283623\n",
      "Percentage completed in (%)  : 87.73770241660151\n",
      "Percentage completed in (%)  : 91.55238513036679\n",
      "Percentage completed in (%)  : 95.36706784413207\n",
      "Percentage completed in (%)  : 99.18175055789735\n",
      "End of Trace\n",
      "Execution Time for the FTL : 517.5725569725037\n",
      "Total Number of GC writes : 23381882\n"
     ]
    }
   ],
   "source": [
    "# Core simulation of trace\n",
    "L2P = {}\n",
    "P2L = {}\n",
    "total_gc_writes = []\n",
    "total_gc_writes.append(0)\n",
    "counter = 0\n",
    "GC_THRESHOLD = int(0.25*len(block_addresses))\n",
    "print(\"GC Threshold set\",GC_THRESHOLD)\n",
    "min_LBA = min(lba_list)\n",
    "closed_blocks = []\n",
    "cur_block = free_list_block.pop(0)\n",
    "global in_gc \n",
    "in_gc = False\n",
    "global gc_writes\n",
    "gc_writes = 0\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "while(counter < len(lba_list)):\n",
    "    lba=int(lba_list[counter]) - min_LBA\n",
    "    if(counter >50000 and counter%50000==0):\n",
    "        print(\"Percentage completed in (%)  :\", (counter/len(lba_list))*100)\n",
    "    if lba in L2P:\n",
    "        invalidate_lba(lba)\n",
    "    cur_block = check_GC(cur_block,in_gc)\n",
    "    map_lba(lba,cur_block)\n",
    "    counter = counter + 1\n",
    "    \n",
    "    \n",
    "print(\"End of Trace\")\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(\"Execution Time for the FTL :\",run_time)\n",
    "print(\"Total Number of GC writes :\",total_gc_writes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
