{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few\\synthetic_dataprep_B_with_deathtime_new_1.0GB_SSD.csv\n",
      "Min LBA in the dataset : 0\n",
      "Max LBA in the dataset : 262144\n",
      "Number of unique LBAs in the data : 262145\n",
      "Number of IO Accesses : 1048580\n"
     ]
    }
   ],
   "source": [
    "# Loading required libraries\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Loading trace : Needs to expanded into 4K chunks\n",
    "path = r'C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few'\n",
    "all_files = glob.glob(os.path.join(path, \"synthetic_dataprep_B_with_deathtime_new_1.0GB_SSD.csv\"))\n",
    "\n",
    "f = all_files[0]  # Change the file name as required\n",
    "print(\"File \" + str(f))\n",
    "cols = ['LBA','Deathtime_RWI']\n",
    "df = pd.read_csv(f,engine='python',skiprows =1,header=None,na_values=['-1'], index_col=False)\n",
    "df.columns = cols\n",
    "df['Deathtime_RWI'] = df['Deathtime_RWI'].replace(np.NaN, -1)\n",
    "lba_list = df['LBA'].tolist()\n",
    "print(\"Min LBA in the dataset :\", min(lba_list))\n",
    "print(\"Max LBA in the dataset :\", max(lba_list))\n",
    "print(\"Number of unique LBAs in the data :\",len(Counter(df['LBA'])))\n",
    "print(\"Number of IO Accesses :\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD Capacity (Available in GB) : 1.1\n",
      "SSD Capacity (Total in GB)     : 1.4\n"
     ]
    }
   ],
   "source": [
    "def round_decimals_up(number,decimals):\n",
    "    \"\"\"\n",
    "    Returns a value rounded up to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor\n",
    "\n",
    "\n",
    "# SSD specifications\n",
    "num_page_addresses = len(Counter(df['LBA']))\n",
    "page_size = 4096\n",
    "page_per_block = 64    \n",
    "GB = 1024*1024*1024\n",
    "SSD_size = num_page_addresses*page_size\n",
    "SSD_size_GB_normal = round_decimals_up(SSD_size/GB,1)\n",
    "over_provisioning_ratio = 0.25 \n",
    "LOG_PAGE_PER_BLOCK = int(math.log(page_per_block,2))\n",
    "SSD_size_full = round_decimals_up((1 + over_provisioning_ratio)*SSD_size_GB_normal,1)\n",
    "print(\"SSD Capacity (Available in GB) :\",SSD_size_GB_normal)\n",
    "print(\"SSD Capacity (Total in GB)     :\",SSD_size_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks good.Go ahead!\n"
     ]
    }
   ],
   "source": [
    "# Make the block,page and physical addresses for normal and Overprovisioned capacity\n",
    "GB = 1024*1024*1024\n",
    "ssd_capacity = SSD_size_full *GB\n",
    "page_addresses = []\n",
    "block_addresses = []\n",
    "block_placement = 0\n",
    "start_counter = -1\n",
    "block_addresses.append(0)\n",
    "\n",
    "while(start_counter < (ssd_capacity/page_size) - page_size):\n",
    "    start_counter = start_counter + 1\n",
    "    page_addresses.append(int(start_counter))\n",
    "    if(block_placement >= page_per_block):\n",
    "        block_addresses.append(int(start_counter))\n",
    "        block_placement = 0\n",
    "\n",
    "    block_placement = block_placement + 1\n",
    "\n",
    "free_list_block = copy.deepcopy(block_addresses)\n",
    "free_list_page = copy.deepcopy(page_addresses)\n",
    "\n",
    "# Defining block_structure\n",
    "valid_bitmap = []\n",
    "write_ptr=0\n",
    "invalid_pages=0\n",
    "block_struct = {}\n",
    "\n",
    "for x in free_list_block:\n",
    "    start_lba = x\n",
    "    valid_bitmap = []\n",
    "    for x in range(page_per_block):\n",
    "        valid_bitmap.append(False)\n",
    "    segment = [start_lba,invalid_pages,valid_bitmap,write_ptr]\n",
    "    block_struct[start_lba]=segment\n",
    "    \n",
    "GC_THRESHOLD = int(0.25*len(block_addresses))\n",
    "if(len(page_addresses)*0.75 < len(Counter(df['LBA']))):\n",
    "    print(\"WARNING...! Not enough blocks. Need to increase SSD Size\")\n",
    "else:\n",
    "    print(\"Looks good.Go ahead!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invalidate_lba(lba):\n",
    "    prev = L2P[lba]\n",
    "    prev_block = (prev >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "    prev_page = prev % page_per_block\n",
    "    block_details = block_struct[prev_block]                                 # Getting block details\n",
    "    block_struct[prev_block][2][prev_page] = False                           # Setting bitmap to False\n",
    "    block_struct[prev_block][1] = block_struct[cur_block][2].count(True)     # Setting invalid pages\n",
    "    L2P.pop(lba)\n",
    "    \n",
    "\n",
    "def map_lba(lba,cur_block):\n",
    "    phys_addr = block_struct[cur_block][0] + block_struct[cur_block][3]\n",
    "    L2P[lba] = phys_addr\n",
    "    P2L[phys_addr] = lba   \n",
    "    block_struct[cur_block][2][block_struct[cur_block][3]] =  True               # Setting Bitmap\n",
    "    block_struct[cur_block][1] =  block_struct[cur_block][2].count(True)         # Setting invalid pages\n",
    "    block_struct[cur_block][3] = block_struct[cur_block][3] + 1                  # Increasing Write pointer\n",
    "    \n",
    "def check_GC (cur_block, in_gc):\n",
    "    if (block_struct[cur_block][3] < page_per_block):\n",
    "        return cur_block\n",
    "    else:\n",
    "        closed_blocks.append(cur_block)\n",
    "        if(len(free_list_block) <= 0):\n",
    "            print(\"FAIL WHILE DOING GC, RAN OUT OF BLOCKS\") \n",
    "        elif (len(free_list_block) <= GC_THRESHOLD):\n",
    "            if(in_gc != True):\n",
    "                if(block_struct[cur_block][3] >= page_per_block):\n",
    "                    cur_block = free_list_block.pop(0)\n",
    "                in_gc = do_greedy_gc(cur_block,in_gc)\n",
    "        if(block_struct[cur_block][3] == (page_per_block)):\n",
    "            cur_block = free_list_block.pop(0)\n",
    "        return cur_block\n",
    "\n",
    "\n",
    "def do_greedy_gc(cur_block,in_gc):\n",
    "    in_gc = True\n",
    "    gc_writes = 0\n",
    "    min_val = float('inf')  \n",
    "    for x in closed_blocks:               \n",
    "        if (block_struct[x][1] < min_val):\n",
    "            min_val = block_struct[x][1]\n",
    "            gc_blk = x\n",
    "\n",
    "    \n",
    "    #found the block with minimal valid pages, move all valid pages\n",
    "    for pg in range(page_per_block):\n",
    "        #figure out the logical addresses for all phys pages in the gc block\n",
    "        phys_addr = block_struct[gc_blk][0] + pg\n",
    "        gc_lba = P2L[phys_addr]\n",
    "        \n",
    "        # Checking for valid bitmap\n",
    "        prev_block = (phys_addr >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "        prev_page = phys_addr % page_per_block\n",
    "        bitmap = block_struct[prev_block][2][prev_page]\n",
    "        # If valid bitmap is True (data is valid), copy to OP capacity, increase GC writes\n",
    "        if (bitmap == True):\n",
    "            invalidate_lba(gc_lba)\n",
    "            #check if we need to get a new block\n",
    "            cur_block = check_GC(cur_block,in_gc)\n",
    "            #move the gc'ed block t-o a new location\n",
    "            map_lba(gc_lba,cur_block)   \n",
    "            gc_writes = gc_writes + 1\n",
    "           \n",
    "            \n",
    "    if(gc_writes > 64):\n",
    "        print(\"GC writes not as expected\", gc_writes)\n",
    "        \n",
    "    # Reset block details, remove from closed list and add to free_list\n",
    "    invalid_pages = 0\n",
    "    valid_bitmap = []\n",
    "    write_ptr = 0\n",
    "    for x in range(page_per_block):\n",
    "        valid_bitmap.append(False)\n",
    "        \n",
    "    block_struct[gc_blk]= [gc_blk,invalid_pages,valid_bitmap,write_ptr]\n",
    "    closed_blocks.remove(gc_blk)\n",
    "    free_list_block.append(gc_blk)\n",
    "    total_gc_writes[0] = total_gc_writes[0] + gc_writes\n",
    "    in_gc = False\n",
    "    return in_gc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Threshold set 1417\n",
      "Percentage completed in (%)  : 19.073413568826414\n",
      "Percentage completed in (%)  : 28.610120353239623\n",
      "Percentage completed in (%)  : 38.14682713765283\n",
      "Percentage completed in (%)  : 47.68353392206603\n",
      "Percentage completed in (%)  : 57.220240706479245\n",
      "Percentage completed in (%)  : 66.75694749089244\n",
      "Percentage completed in (%)  : 76.29365427530566\n",
      "Percentage completed in (%)  : 85.83036105971887\n",
      "Percentage completed in (%)  : 95.36706784413207\n",
      "End of Trace\n",
      "Execution Time for the FTL : 251.75602650642395\n",
      "Total Number of GC writes : 9346492\n"
     ]
    }
   ],
   "source": [
    "# Core simulation of trace\n",
    "L2P = {}\n",
    "P2L = {}\n",
    "total_gc_writes = []\n",
    "total_gc_writes.append(0)\n",
    "counter = 0\n",
    "GC_THRESHOLD = int(0.25*len(block_addresses))\n",
    "print(\"GC Threshold set\",GC_THRESHOLD)\n",
    "min_LBA = min(lba_list)\n",
    "closed_blocks = []\n",
    "cur_block = free_list_block.pop(0)\n",
    "block_details = block_struct[cur_block]\n",
    "global in_gc \n",
    "in_gc = False\n",
    "global gc_writes\n",
    "gc_writes = 0\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "while(counter < len(lba_list)):\n",
    "    lba=int(lba_list[counter]) - min_LBA\n",
    "    if(counter >100000 and counter%100000==0):\n",
    "        print(\"Percentage completed in (%)  :\", (counter/len(lba_list))*100)\n",
    "    if lba in L2P:\n",
    "        invalidate_lba(lba)\n",
    "    cur_block = check_GC(cur_block,in_gc)\n",
    "    map_lba(lba,cur_block)\n",
    "    counter = counter + 1\n",
    "    \n",
    "    \n",
    "print(\"End of Trace\")\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(\"Execution Time for the FTL :\",run_time)\n",
    "print(\"Total Number of GC writes :\",total_gc_writes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done..!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done..!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
