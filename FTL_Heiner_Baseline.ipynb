{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. GB should be 1024*1024*1024 but it probably doesn't matter as long\n",
    "# as you round NUMBER_OF_BLOCKS to a whole number - D\n",
    "# 1. Change page_per_block to 64 (current standard)\n",
    "# 2. print the variable GC_THRESHOLD\n",
    "# 3. print the count of unique LBAs in the trace\n",
    "# 4. print the smallest and largest LBA (if the smallest LBA is X then\n",
    "# you want to subtract X from all LBAs so they range from 0 to\n",
    "# LARGEST_LBA-X)\n",
    "# 5. Change the SSD size so that the number of LBA==LARGEST_LBA\n",
    "# 6. fix major bug in gc, the code down below must be indented to the\n",
    "# left. You do not want to perform GC for every block in the system but\n",
    "# only for the block with the smallest number of valid pages.\n",
    "# 7. make sure  print(gc_writes) prints a number smaller than 64\n",
    "# (maximum number of valid pages per block)\n",
    "# 8. Generate two synthetic benchmarks\n",
    "# 8a) Write the entire LBA space 10 times, sequentially (make smaller\n",
    "# SSD so it doesn't take too long)\n",
    "# 8b) Write the entire LBA space 10 times, randomly (e.g. just randomly\n",
    "# pick LBA and the total number of writes should be 10*LARGEST_LBA)\n",
    "# 9. Print the total number of GC writes for 8a (expected zero) and 8b\n",
    "# (expected many) and the real trace at the end of the simulation\n",
    "# 10. let me know if you have questions\n",
    "\n",
    "#         #found the block with minimal valid pages, move all valid pages\n",
    "#         for pg in range(page_per_block):\n",
    "#             #figure out the logical addresses for all phys pages in the gc block\n",
    "#             phys_addr = block_struct[x][0] + pg\n",
    "#             gc_lba = P2L[phys_addr]\n",
    "#             invalidate_lba(gc_lba)\n",
    "#             #check if we need to get a new block\n",
    "#             cur_block = check_GC(cur_block,in_gc)\n",
    "#             #move the gc'ed block t-o a new location\n",
    "#             map_lba(gc_lba,cur_block)\n",
    "#             gc_writes = gc_writes + 1\n",
    "#         block_struct[gc_blk][3]=1\n",
    "#         closed_blocks.remove(gc_blk)\n",
    "#         free_list_block.append(gc_blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with file C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few\\synthetic_dataprep_A_deathtime_added.csv\n",
      "Min LBA in the dataset : 0\n",
      "Max LBA in the dataset : 1216608\n",
      "Number of unique LBAs in the data : 1216609\n",
      "Number of IO Accesses : 12166090\n"
     ]
    }
   ],
   "source": [
    "# Loading required libraries\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Loading trace : Needs to expanded into 4K chunks\n",
    "path = r'C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few'\n",
    "all_files = glob.glob(os.path.join(path, \"synthetic_dataprep_A_deathtime_added.csv\"))\n",
    "\n",
    "f = all_files[0]  # Change the file name as required\n",
    "print(\"Working with file \" + str(f))\n",
    "cols = ['IO_num','LBA','Deathtime_RWI']\n",
    "df = pd.read_csv(f,engine='python',skiprows =1,header=None,na_values=['-1'], index_col=False)\n",
    "df.columns = cols\n",
    "df['Deathtime_RWI'] = df['Deathtime_RWI'].replace(np.NaN, -1)\n",
    "lba_list = df['LBA'].tolist()\n",
    "print(\"Min LBA in the dataset :\", min(lba_list))\n",
    "print(\"Max LBA in the dataset :\", max(lba_list))\n",
    "print(\"Number of unique LBAs in the data :\",len(Counter(df['LBA'])))\n",
    "print(\"Number of IO Accesses :\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find SSD size suitable for the Test\n",
    "# lba_range_data = max(lba_list) - min(lba_list)\n",
    "# TB = 1024*1024*1024*1024\n",
    "# GB = 1024*1024*1024\n",
    "\n",
    "# SSD_size_TB = math.ceil(lba_range_data/TB)\n",
    "# SSD_size_GB = math.ceil(lba_range_data/GB)\n",
    "\n",
    "# print(\"LBA range in TB\", SSD_size_TB)\n",
    "# print(\"LBA range in GB\", SSD_size_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217497\n",
      "19024\n"
     ]
    }
   ],
   "source": [
    "# SSD specifications\n",
    "page_size = 4096\n",
    "page_per_block = 64                          # Hyperparameter \n",
    "over_provisioning_ratio = 0.3 \n",
    "GB = 1024*1024*1024\n",
    "SSD_size_GB = 4.66 * GB\n",
    "ssd_capacity = SSD_size_GB                    # Hyperparameter                     \n",
    "LOG_PAGE_PER_BLOCK = int(math.log(page_per_block,2))\n",
    "\n",
    "\n",
    "# Make the block,page and physical addresses for normal and Overprovisioned capacity\n",
    "page_addresses = []\n",
    "block_addresses = []\n",
    "block_placement = 0\n",
    "start_counter = -1\n",
    "block_addresses.append(0)\n",
    "\n",
    "while(start_counter < (ssd_capacity/page_size) - page_size):\n",
    "    start_counter = start_counter + 1\n",
    "    page_addresses.append(int(start_counter))\n",
    "    if(block_placement >= page_per_block):\n",
    "        block_addresses.append(int(start_counter))\n",
    "        block_placement = 0\n",
    "\n",
    "    block_placement = block_placement + 1\n",
    "\n",
    "free_list_block = copy.deepcopy(block_addresses)\n",
    "free_list_page = copy.deepcopy(page_addresses)\n",
    "\n",
    "\n",
    "print(len(page_addresses))\n",
    "print(len(block_addresses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19024\n"
     ]
    }
   ],
   "source": [
    "# Defining block_structure\n",
    "valid_bitmap = []\n",
    "write_ptr=0\n",
    "invalid_pages=0\n",
    "block_struct = {}\n",
    "\n",
    "for x in free_list_block:\n",
    "    start_lba = x\n",
    "    for x in range(page_per_block):\n",
    "        valid_bitmap.append(False)\n",
    "    segment = [start_lba,invalid_pages,valid_bitmap,write_ptr]\n",
    "    block_struct[start_lba]=segment\n",
    "    \n",
    "print(len(block_struct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block structure : Dictionary  # Key: Block_address_start    #Value: [valid_pages,valid_bitmap,write_ptr]\n",
    "\n",
    "def invalidate_lba(lba):\n",
    "    prev = L2P[lba]\n",
    "    #note above how phys addresses are formed/concatenated\n",
    "    prev_block = (prev >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "    prev_page = prev % page_per_block\n",
    "    block_details = block_struct[prev_block]                                 # Getting block details\n",
    "    block_struct[prev_block][1] = block_struct[prev_block][1] - 1            # Decreasing invalid pages\n",
    "    block_struct[prev_block][2][prev_page] = False                          # Setting bitmap to False\n",
    "    L2P.pop(lba)\n",
    "    \n",
    "    \n",
    "#map LBA to phys\n",
    "def map_lba(lba,cur_block):\n",
    "    page_per_block = 64  \n",
    "    if(isinstance(cur_block, int) == False):\n",
    "        print(\"BAD\")\n",
    "    if (block_struct[cur_block][3] >= (page_per_block)):\n",
    "        print(\"It happened\")\n",
    "        print(block_struct[cur_block])\n",
    "    phys_addr = block_struct[cur_block][0] + (block_struct[cur_block][3])\n",
    "    L2P[lba] = phys_addr\n",
    "    P2L[phys_addr] = lba   \n",
    "    block_struct[cur_block][2][block_struct[cur_block][3]] = True             # Setting Bitmap\n",
    "    block_struct[cur_block][1] = block_struct[cur_block][1] + 1               # Increasing invalid pages\n",
    "    block_struct[cur_block][3] = block_struct[cur_block][3] + 1               # Increasing Write pointer\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#check if we need to close/open block. Do not perform GC if we are already\n",
    "#doing gc\n",
    "def check_GC (cur_block, in_gc):\n",
    "    if (block_struct[cur_block][3] < (page_per_block)):\n",
    "        return cur_block\n",
    "    else:\n",
    "        closed_blocks.append(cur_block)\n",
    "        if(len(free_list_block) == 0):\n",
    "            print(\"FAIL WHILE DOING GC, RAN OUT OF BLOCKS\") \n",
    "        elif (len(free_list_block) <= GC_THRESHOLD):\n",
    "#             print(GC_THRESHOLD)\n",
    "            if(in_gc != True):\n",
    "#                 print(\"GC called\")\n",
    "                in_gc = do_greedy_gc(cur_block,in_gc)\n",
    "#                 print(cur_block)\n",
    "        elif(len(free_list_block) == 0):\n",
    "            print(\"FAIL WHILE DOING GC, RAN OUT OF BLOCKS\")     \n",
    "        if(block_struct[cur_block][3] == (page_per_block)):\n",
    "            cur_block = free_list_block.pop(0)\n",
    "            if(isinstance(cur_block, int) == False):\n",
    "                print(cur_block)\n",
    "            return cur_block\n",
    "\n",
    "\n",
    "\n",
    "def do_greedy_gc(cur_block,in_gc):\n",
    "    in_gc = True\n",
    "    gc_writes = 0\n",
    "    for x in closed_blocks:\n",
    "        min_val = float('inf')              \n",
    "        if (block_struct[x][1] < min_val):\n",
    "            min_val = block_struct[x][1]\n",
    "        gc_blk = x\n",
    "#     print(\"Found the block with minimum valid pages\", gc_blk)\n",
    "    #found the block with minimal valid pages, move all valid pages\n",
    "    for pg in range(page_per_block):\n",
    "        #figure out the logical addresses for all phys pages in the gc block\n",
    "        phys_addr = block_struct[x][0] + pg\n",
    "        gc_lba = P2L[phys_addr]\n",
    "        invalidate_lba(gc_lba)\n",
    "        # Checking for valid bitmap\n",
    "        prev_block = (phys_addr >> LOG_PAGE_PER_BLOCK)*page_per_block\n",
    "        prev_page = phys_addr % page_per_block\n",
    "        bitmap = block_struct[prev_block][2][prev_page]\n",
    "        # If valid bitmap is True (data is valid), copy to OP capacity, increase GC writes\n",
    "        if (bitmap != False):\n",
    "            gc_writes = gc_writes + 1\n",
    "            #check if we need to get a new block\n",
    "            cur_block = check_GC(cur_block,in_gc)\n",
    "            #move the gc'ed block t-o a new location\n",
    "            map_lba(gc_lba,cur_block)   \n",
    "            gc_writes = gc_writes + 1\n",
    "    \n",
    "    gc_file = r'C:\\Users\\cchak\\Desktop\\Data_ECML\\VDI Traces\\selected_few\\GC_write_stats_FTL_Baseline_B.txt'\n",
    "    file_object = open(gc_file, 'a')\n",
    "    # Append new GC writes\n",
    "    file_object.write(str(gc_writes))\n",
    "    # Close the file\n",
    "    file_object.close()\n",
    "    # Reset block details, remove from closed list and add to free_list\n",
    "    block_struct[gc_blk]= [prev_block,invalid_pages,valid_bitmap,write_ptr]\n",
    "    closed_blocks.remove(gc_blk)\n",
    "    free_list_block.append(gc_blk)\n",
    "    in_gc = False\n",
    "    if(gc_writes > 0):\n",
    "        print(\"GC writes not as expected\", gc_writes)\n",
    "    return in_gc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Threshold set 3804\n",
      "Percentage completed in (%)  : 1.6439135334359682\n",
      "Percentage completed in (%)  : 2.4658703001539526\n",
      "Percentage completed in (%)  : 3.2878270668719365\n",
      "Percentage completed in (%)  : 4.109783833589921\n",
      "Percentage completed in (%)  : 4.931740600307905\n",
      "Percentage completed in (%)  : 5.753697367025889\n",
      "Percentage completed in (%)  : 6.575654133743873\n",
      "Percentage completed in (%)  : 7.397610900461858\n",
      "Percentage completed in (%)  : 8.219567667179842\n",
      "Percentage completed in (%)  : 9.041524433897825\n"
     ]
    }
   ],
   "source": [
    "# Core simulation of trace\n",
    "\n",
    "L2P = {}\n",
    "P2L = {}\n",
    "counter = 0\n",
    "GC_THRESHOLD = int(0.2*len(block_addresses))\n",
    "print(\"GC Threshold set\",GC_THRESHOLD)\n",
    "min_LBA = min(lba_list)\n",
    "closed_blocks = []\n",
    "cur_block = free_list_block.pop(0)\n",
    "block_details = block_struct[cur_block]\n",
    "global in_gc \n",
    "in_gc = False\n",
    "global gc_writes\n",
    "gc_writes = 0\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "while(counter < len(lba_list)):\n",
    "    lba=int(lba_list[counter]) - min_LBA\n",
    "    if(counter >100000 and counter%100000==0):\n",
    "        print(\"Percentage completed in (%)  :\", (counter/len(lba_list))*100)\n",
    "    if lba in L2P:\n",
    "        invalidate_lba(lba)\n",
    "    last_cur_block = cur_block \n",
    "    cur_block = check_GC(cur_block,in_gc)\n",
    "    if(isinstance(cur_block, int) == False):\n",
    "        if(block_struct[last_cur_block][3] != page_per_block):\n",
    "            cur_block = free_list_block.pop(0)\n",
    "        else:\n",
    "            print(\"Something happened after block :\",last_cur_block)\n",
    "    map_lba(lba,cur_block)\n",
    "    #print(block_struct[cur_block])\n",
    "    counter = counter + 1\n",
    "print(\"End of Trace\")\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(\"Execution Time for the FTL :\",run_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done...Sanity Check complete!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-1.13",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
